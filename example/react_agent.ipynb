{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexplain how to use kenkenpa with the example of React-Agent.\\nhttps://langchain-ai.github.io/langgraph/\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "explain how to use kenkenpa with the example of React-Agent.\n",
    "https://langchain-ai.github.io/langgraph/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Tool node as usual.\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"Call to surf the web.\"\"\"\n",
    "\n",
    "    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
    "        return \"It's 60 degrees and foggy.\"\n",
    "    return \"It's 90 degrees and sunny.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the factory function for the Tool node.\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools = {\n",
    "    \"search_function\":search,\n",
    "    }\n",
    "\n",
    "def gen_tool_node(factory_parameter,flow_parameter):\n",
    "    functions = factory_parameter['functions']\n",
    "\n",
    "    tool_functions = []\n",
    "    for function in functions:\n",
    "        tool_functions.append(tools[function])\n",
    "\n",
    "    tool_node = ToolNode(tool_functions)\n",
    "    return tool_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the factory function for the agent node.\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def gen_agent(factory_parameter,flow_parameter):\n",
    "    functions = factory_parameter['functions']\n",
    "\n",
    "    tool_functions = []\n",
    "    for function in functions:\n",
    "        tool_functions.append(tools[function])\n",
    "\n",
    "     # Setting up the LLM\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\"\n",
    "    )\n",
    "\n",
    "    model = model.bind_tools(tool_functions)\n",
    "\n",
    "    # Define the function that calls the model\n",
    "    def call_model(state):\n",
    "        messages = state['messages']\n",
    "        response = model.invoke(messages)\n",
    "        # We return a list, because this will get added to the existing list\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    return call_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate whether the last message is a tool call instead of should_continue.\n",
    "def is_tool_message(state, config, **kwargs):\n",
    "    \"\"\"Evaluate whether the last message is a tool call.\"\"\"\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    if last_message.tool_calls:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create structured data representing a StateGraph.\n",
    "graph_settings = {\n",
    "    \"graph_type\":\"stategraph\",\n",
    "    \"flow_parameter\":{\n",
    "        \"name\":\"React-Agent\",\n",
    "        \"state\" : [\n",
    "            {\n",
    "                \"field_name\": \"messages\", # state name\n",
    "                \"type\": \"list\", # type(*1)\n",
    "                \"reducer\":\"add_messages\" # reducer(*2)\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    \"flows\":[\n",
    "        { # agent node(*3)\n",
    "            \"graph_type\":\"node\",\n",
    "            \"flow_parameter\":{\n",
    "                \"name\":\"agent\",\n",
    "                \"factory\":\"agent_node_factory\",\n",
    "            },\n",
    "            \"factory_parameter\" : {\n",
    "                \"functions\":[\n",
    "                    \"search_function\",\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "        { # tools node(*3)\n",
    "            \"graph_type\":\"node\",\n",
    "            \"flow_parameter\":{\n",
    "                \"name\":\"tools\",\n",
    "                \"factory\":\"tool_node_factory\",\n",
    "            },\n",
    "            \"factory_parameter\":{\n",
    "                \"functions\":[\n",
    "                    \"search_function\",\n",
    "                ],\n",
    "            },\n",
    "        },\n",
    "        {# edge START -> agent\n",
    "            \"graph_type\":\"edge\",\n",
    "            \"flow_parameter\":{\n",
    "                \"start_key\":\"START\",\n",
    "                \"end_key\":\"agent\"\n",
    "            },\n",
    "        },\n",
    "        {# coditional edge \n",
    "            \"graph_type\":\"configurable_conditional_edge\",\n",
    "            \"flow_parameter\":{\n",
    "                \"start_key\":\"agent\",\n",
    "                \"conditions\":[\n",
    "                    {\n",
    "                        # Transition to the tools node if the result of is_tool_message is True.\n",
    "                        \"expression\": {\n",
    "                            \"eq\": [{\"type\": \"function\", \"name\": \"is_tool_message_function\"}, True], # *4\n",
    "                        },\n",
    "                        \"result\": \"tools\"\n",
    "                    },\n",
    "                    {\"default\": \"END\"} \n",
    "                ]\n",
    "            },\n",
    "        },\n",
    "        {# edge tools -> agent\n",
    "            \"graph_type\":\"edge\",\n",
    "            \"flow_parameter\":{\n",
    "                \"start_key\":\"tools\",\n",
    "                \"end_key\":\"agent\"\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "graph\n",
      "        +-----------+         \n",
      "        | __start__ |         \n",
      "        +-----------+         \n",
      "              *               \n",
      "              *               \n",
      "              *               \n",
      "          +-------+           \n",
      "          | agent |           \n",
      "          +-------+           \n",
      "         .         .          \n",
      "       ..           ..        \n",
      "      .               .       \n",
      "+-------+         +---------+ \n",
      "| tools |         | __end__ | \n",
      "+-------+         +---------+ \n",
      "The current weather in San Francisco is 60 degrees and foggy.\n"
     ]
    }
   ],
   "source": [
    "# Generate a StateGraphBuilder from graph_settings.\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import  add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from kenkenpa.builder import StateGraphBuilder\n",
    "\n",
    "# Instantiate the StateGraphBuilder\n",
    "stategraph_builder = StateGraphBuilder(graph_settings)\n",
    "\n",
    "# Some preparations are needed to generate a compilable StateGraph.\n",
    "# *1. Register the types to be used. (list is reserved, but it is written for explanation purposes.)\n",
    "#stategraph_builder.add_type(\"list\", list)\n",
    "\n",
    "# *2. Register the reducers to be used.\n",
    "stategraph_builder.add_reducer(\"add_messages\",add_messages)\n",
    "\n",
    "# *3. Register the Node Factories.\n",
    "stategraph_builder.add_node_factory(\"agent_node_factory\",gen_agent)\n",
    "stategraph_builder.add_node_factory(\"tool_node_factory\",gen_tool_node)\n",
    "\n",
    "# *4. Register the evaluation functions as well.\n",
    "stategraph_builder.add_evaluete_function(\"is_tool_message_function\", is_tool_message,)\n",
    "\n",
    "# You can obtain a compilable StateGraph with the gen_stategraph() method.\n",
    "stategraph = stategraph_builder.gen_stategraph()\n",
    "\n",
    "# From here, write the code following the general usage of LangGraph.\n",
    "memory = MemorySaver()\n",
    "app =  stategraph.compile(checkpointer=memory,debug=False)\n",
    "\n",
    "print(f\"\\ngraph\")\n",
    "app.get_graph().print_ascii()\n",
    "final_state = app.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]},\n",
    "    config={\"configurable\": {\"thread_id\": 42}}\n",
    ")\n",
    "print(final_state[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
