{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Based on the following code, we will explain how to use the SendAPI.\n",
    "Some parts of the test code reuse the code listed at the following URL.\n",
    "https://langchain-ai.github.io/langgraph/how-tos/map-reduce/\n",
    "\"\"\"\n",
    "import operator\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.types import Send\n",
    "\n",
    "from kenkenpa.builder import StateGraphBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_prompt = \"\"\"Generate a comma separated list of between 2 and 5 examples related to: {topic}.\"\"\"\n",
    "joke_prompt = \"\"\"Generate a joke about {subject}\"\"\"\n",
    "best_joke_prompt = \"\"\"Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one.\n",
    "\n",
    "{jokes}\"\"\"\n",
    "\n",
    "class Subjects(BaseModel):\n",
    "    subjects: list[str]\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    joke: str\n",
    "\n",
    "class BestJoke(BaseModel):\n",
    "    id: int = Field(description=\"Index of the best joke. starting with 0\",ge=0)\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "class OverallState(TypedDict):\n",
    "    topic: str\n",
    "    subjects: list\n",
    "    jokes: Annotated[list, operator.add]\n",
    "    best_selected_joke: str\n",
    "\n",
    "class JokeState(TypedDict):\n",
    "    subject: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topics(state: OverallState):\n",
    "    prompt = subjects_prompt.format(topic=state[\"topic\"])\n",
    "    response = model.with_structured_output(Subjects).invoke(prompt)\n",
    "    return {\"subjects\": response.subjects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_joke(state: JokeState):\n",
    "    prompt = joke_prompt.format(subject=state[\"subject\"])\n",
    "    response = model.with_structured_output(Joke).invoke(prompt)\n",
    "    return {\"jokes\": [response.joke]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :pencil: Define continue_to_jokes as a callable evaluation function.\n",
    "def continue_to_jokes(state:OverallState, config, **kwargs):\n",
    "    return [Send(\"generate_joke\",{\"subject\":s}) for s in state[\"subjects\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_joke(state: OverallState):\n",
    "    jokes = \"\\n\\n\".join(state[\"jokes\"])\n",
    "    prompt = best_joke_prompt.format(topic=state[\"topic\"], jokes=jokes)\n",
    "    response = model.with_structured_output(BestJoke).invoke(prompt)\n",
    "    return {\"best_selected_joke\": state[\"jokes\"][response.id]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# :pencil: Define a factory function.\n",
    "def gen_generate_topics(factory_parameter,flow_parameter):\n",
    "    return generate_topics\n",
    "\n",
    "def gen_generate_joke(factory_parameter,flow_parameter):\n",
    "    return generate_joke\n",
    "\n",
    "def gen_best_joke(factory_parameter,flow_parameter):\n",
    "    return best_joke\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_settings = {\n",
    "    \"graph_type\":\"stategraph\",\n",
    "    \"flow_parameter\":{\n",
    "        \"name\":\"React-Agent\",\n",
    "        # :pencil: Define the fields equivalent to OverallState here.\n",
    "        \"state\" : [\n",
    "            {\n",
    "                \"field_name\": \"topic\",\n",
    "                \"type\": \"str\",\n",
    "            },\n",
    "            {\n",
    "                \"field_name\": \"subjects\",\n",
    "                \"type\": \"list\",\n",
    "            },\n",
    "            {\n",
    "                \"field_name\": \"jokes\",\n",
    "                \"type\": \"list\",\n",
    "                \"reducer\":\"operator_add\"\n",
    "            },\n",
    "            {\n",
    "                \"field_name\": \"best_selected_joke\",\n",
    "                \"type\": \"str\",\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    \"flows\":[\n",
    "        { # generate_topics node\n",
    "            \"graph_type\":\"node\",\n",
    "            \"flow_parameter\":{\n",
    "                \"name\":\"generate_topics\",\n",
    "                \"factory\":\"gen_generate_topics\",\n",
    "            },\n",
    "        },\n",
    "        { # generate_joke node\n",
    "            \"graph_type\":\"node\",\n",
    "            \"flow_parameter\":{\n",
    "                \"name\":\"generate_joke\",\n",
    "                \"factory\":\"gen_generate_joke\",\n",
    "            },\n",
    "        },\n",
    "        { # best_joke node\n",
    "            \"graph_type\":\"node\",\n",
    "            \"flow_parameter\":{\n",
    "                \"name\":\"best_joke\",\n",
    "                \"factory\":\"gen_best_joke\",\n",
    "            },\n",
    "        },\n",
    "        {# edge START -> generate_topics\n",
    "            \"graph_type\":\"edge\",\n",
    "            \"flow_parameter\":{\n",
    "                \"start_key\":\"START\",\n",
    "                \"end_key\":\"generate_topics\"\n",
    "            },\n",
    "        },\n",
    "        {# coditional edge generate_topics -> continue_to_jokes\n",
    "            \"graph_type\":\"configurable_conditional_edge\",\n",
    "            \"flow_parameter\":{\n",
    "                \"start_key\":\"generate_topics\",\n",
    "                \"path_map\":[\"generate_joke\"], # :pencil: Specify the path_map\n",
    "                \"conditions\":[\n",
    "                    # :pencil: Only set the default to call continue_to_jokes\n",
    "                    # without defining an evaluation expression in the conditions.\n",
    "                    {\"default\": {\"type\": \"function\", \"name\": \"continue_to_jokes\"}} \n",
    "                ]\n",
    "            },\n",
    "        },\n",
    "        {# edge generate_joke -> best_joke\n",
    "            \"graph_type\":\"edge\",\n",
    "            \"flow_parameter\":{\n",
    "                \"start_key\":\"generate_joke\",\n",
    "                \"end_key\":\"best_joke\"\n",
    "            },\n",
    "        },\n",
    "        {# edge best_joke -> END\n",
    "            \"graph_type\":\"edge\",\n",
    "            \"flow_parameter\":{\n",
    "                \"start_key\":\"best_joke\",\n",
    "                \"end_key\":\"END\"\n",
    "            },\n",
    "        },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "graph\n",
      "   +-----------+     \n",
      "   | __start__ |     \n",
      "   +-----------+     \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "+-----------------+  \n",
      "| generate_topics |  \n",
      "+-----------------+  \n",
      "          .          \n",
      "          .          \n",
      "          .          \n",
      " +---------------+   \n",
      " | generate_joke |   \n",
      " +---------------+   \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "   +-----------+     \n",
      "   | best_joke |     \n",
      "   +-----------+     \n",
      "          *          \n",
      "          *          \n",
      "          *          \n",
      "    +---------+      \n",
      "    | __end__ |      \n",
      "    +---------+      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_topics': {'subjects': ['Cats', 'Dogs', 'Elephants', 'Dolphins', 'Tigers']}}\n",
      "{'generate_joke': {'jokes': [\"Why did the dog sit in the shade? Because he didn't want to become a hot dog!\"]}}\n",
      "{'generate_joke': {'jokes': ['Why did the dolphin bring a towel to the party? Because it wanted to have a whale of a time!']}}\n",
      "{'generate_joke': {'jokes': ['Why did the tiger eat the tightrope walker? Because he wanted a well-balanced meal!']}}\n",
      "{'generate_joke': {'jokes': [\"Why don't elephants use computers? Because they're afraid of the mouse!\"]}}\n",
      "{'generate_joke': {'jokes': ['Why did the cat sit on the computer? Because it wanted to keep an eye on the mouse!']}}\n",
      "{'best_joke': {'best_selected_joke': 'Why did the dolphin bring a towel to the party? Because it wanted to have a whale of a time!'}}\n"
     ]
    }
   ],
   "source": [
    "# Generate the StateGraphBuilder from graph_settings.\n",
    "stategraph_builder = StateGraphBuilder(graph_settings)\n",
    "\n",
    "# addタイプ\n",
    "stategraph_builder.add_type(\"OverallState\",OverallState)\n",
    "\n",
    "# Register the reducer to be used in the StateGraphBuilder.\n",
    "stategraph_builder.add_reducer(\"operator_add\",operator.add)\n",
    "\n",
    "# Register the node factory with the stategraph_builder.\n",
    "stategraph_builder.add_node_factory(\"gen_generate_topics\",gen_generate_topics)\n",
    "stategraph_builder.add_node_factory(\"gen_generate_joke\",gen_generate_joke)\n",
    "stategraph_builder.add_node_factory(\"gen_best_joke\",gen_best_joke)\n",
    "\n",
    "# Similarly, the evaluation function is also registered.\n",
    "stategraph_builder.add_evaluete_function(\"continue_to_jokes\", continue_to_jokes)\n",
    "\n",
    "# The gen_stategraph method generates a compilable StateGraph.\n",
    "stategraph = stategraph_builder.gen_stategraph()\n",
    "\n",
    "# From here on, we will write the code following the general usage of LangGraph.\n",
    "# Please note that this library does not involve config and checkpointer.\n",
    "app = stategraph.compile()\n",
    "print(f\"\\ngraph\")\n",
    "app.get_graph().print_ascii()\n",
    "\n",
    "# Call the graph: here we call it to generate a list of jokes\n",
    "for s in app.stream({\"topic\": \"animals\"}):\n",
    "    print(s)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
